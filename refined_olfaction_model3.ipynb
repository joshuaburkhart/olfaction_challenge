# ------------------- Imports & Drive Mount -------------------
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import SparsePCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import lightgbm as lgb
from google.colab import drive

# Mount Drive
drive.mount('/content/drive')
DATA_DIR = '/content/drive/MyDrive/olfaction_challenge_data/'

# ------------------- Load Data -------------------
mordred = pd.read_csv(os.path.join(DATA_DIR, 'Mordred_Descriptors.csv'), index_col=0, encoding='latin1')
components = pd.read_csv(os.path.join(DATA_DIR, 'TASK2_Component_definition.csv'))
stimulus_def = pd.read_csv(os.path.join(DATA_DIR, 'TASK2_Stimulus_definition.csv'))
train_data = pd.read_csv(os.path.join(DATA_DIR, 'TASK2_Train_mixture_Dataset.csv.csv'))
leaderboard_form = pd.read_csv(os.path.join(DATA_DIR, 'TASK2_Leaderboard_set_Submission_form.csv'))
leaderboard_truth = pd.read_csv(os.path.join(DATA_DIR, 'TASK2_Leaderboard_ActualValue.csv'))

# ------------------- Preprocess Mordred -------------------
mordred = mordred.apply(pd.to_numeric, errors='coerce')

# ------------------- Feature Extraction -------------------
def get_stimulus_features(stimulus_id):
row = stimulus_def[stimulus_def['id'] == stimulus_id]
if row.empty:
return None
component_ids = row.iloc[0, 1].split(';')
feats = []
for cid in component_ids:
try:
cid_int = int(cid)
comp = components[components['id'] == cid_int]
if comp.empty:
continue
mol_cid = comp['CID'].values[0]
if mol_cid in mordred.index:
feats.append(mordred.loc[mol_cid])
except:
continue
if not feats:
return None
return pd.DataFrame(feats).mean(skipna=True)

# ------------------- Extract Features -------------------
train_X, train_y = [], []
for _, row in tqdm(train_data.iterrows(), total=len(train_data), desc="Extracting train features"):
feats = get_stimulus_features(row['stimulus'])
if feats is not None:
train_X.append(feats.values)
train_y.append(row.iloc[3:].values)

lb_X, lb_y = [], []
for _, row in tqdm(leaderboard_truth.iterrows(), total=len(leaderboard_truth), desc="Extracting leaderboard features"):
feats = get_stimulus_features(row['stimulus'])
if feats is not None:
lb_X.append(feats.values)
lb_y.append(row.iloc[1:].values)

# ------------------- Prepare Combined Dataset -------------------
X_all = pd.DataFrame(train_X + lb_X)
y_all = np.array(train_y + lb_y)

imputer = SimpleImputer(strategy='median')
X_all = imputer.fit_transform(X_all)
scaler = StandardScaler()
X_all = scaler.fit_transform(X_all)

spca = SparsePCA(n_components=64, random_state=42, n_jobs=-1, alpha=1)
X_all = spca.fit_transform(X_all)

# ------------------- Filter Low-Variance Targets -------------------
target_var = np.var(y_all, axis=0)
y_all = y_all[:, target_var >= 1e-6]

# ------------------- Train/Val Split -------------------
X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=42)

# ------------------- Train Models -------------------
models = []
val_preds = np.zeros_like(y_val)
for i in tqdm(range(y_train.shape[1]), desc="Training models"):
model = lgb.LGBMRegressor(
	objective='regression',
	n_estimators=300,
	learning_rate=0.05,
	max_depth=10,
	random_state=42,
	verbosity=-1
	)
	model.fit(X_train, y_train[:, i])
	val_preds[:, i] = np.clip(model.predict(X_val), 0, 5)
	models.append(model)

	# ------------------- Evaluation -------------------
	rmse = np.sqrt(np.mean((y_val - val_preds) ** 2))
	print(f"\nOverall Validation RMSE: {rmse:.4f}")

	per_target_rmse = np.sqrt(np.mean((y_val - val_preds) ** 2, axis=0))
	print("\nPer-Target RMSE:")
	for name, score in zip(leaderboard_truth.columns[1:], per_target_rmse):
	print(f"{name}: {score:.4f}")

	# ------------------- Predict Leaderboard -------------------
	mean_train_pred = np.clip(y_train.mean(axis=0), 0, 5)
	pred_rows = []
	missing = 0
	for sid in tqdm(leaderboard_form['stimulus'], desc="Predicting leaderboard"):
	feats = get_stimulus_features(sid)
	if feats is None:
	pred_rows.append(mean_train_pred)
	missing += 1
	else:
	feats = feats.values.reshape(1, -1)
	feats = imputer.transform(feats)
	feats = scaler.transform(feats)
	feats = spca.transform(feats)
	preds = [np.clip(m.predict(feats)[0], 0, 5) for m in models]
	pred_rows.append(preds)

	# ------------------- Save Predictions -------------------
	submission = leaderboard_form.copy()
	submission.iloc[:, 1:] = pred_rows
	refined_path = os.path.join(DATA_DIR, 'TASK2_Leaderboard_Predictions_Refined.csv')
	submission.to_csv(refined_path, index=False)
	print(f"\nSaved refined predictions to: {refined_path}")
	print(f"Used mean fallback for {missing} stimuli.")

